{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'./')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "medmnist_dir = os.path.join(project_dir, 'modules/MedMNIST')\n",
    "if medmnist_dir not in sys.path:\n",
    "    sys.path.append(medmnist_dir)\n",
    "\n",
    "ipdl_dir = os.path.join(project_dir, 'modules/IPDL')\n",
    "if ipdl_dir not in sys.path:\n",
    "    sys.path.append(ipdl_dir)    \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment.classifier import PCAE\n",
    "\n",
    "pcae_exp = PCAE(os.path.join(project_dir, 'data/PCAE/weights/AE/BREAST.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO\n",
    "\n",
    "data_flag = 'breastmnist'\n",
    "download = True\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "data_transform = Compose([\n",
    "    Resize((64, 64)),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "data_flag = 'breastmnist'\n",
    "download = True\n",
    "\n",
    "\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
    "eval_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
    "test_dataset = DataClass(split='test', transform=data_transform, download=download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "sampling_strategies = [{0: 128, 1: 128}, {0: 16, 1: 16}]\n",
    "datasets = [train_dataset, eval_dataset]\n",
    "\n",
    "for idx, dataset in enumerate(datasets):\n",
    "    x = dataset.imgs\n",
    "    y = dataset.labels\n",
    "\n",
    "    sampling_strategy = sampling_strategies[idx]\n",
    "    undersampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=123)\n",
    "    X_resampled, y_resampled = undersampler.fit_resample(x.reshape((x.shape[0], -1)), y.flatten())\n",
    "\n",
    "    dataset.imgs = X_resampled.reshape((-1, x.shape[1], x.shape[2]))\n",
    "    dataset.labels = y_resampled\n",
    "    # dataset.labels = y_resampled.reshape((-1, y.shape[1]))\n",
    "\n",
    "print('Train Dataset: {} samples'.format(len(train_dataset)))\n",
    "print('Eval Dataset: {} samples'.format(len(eval_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "eval_loader = DataLoader(dataset=eval_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "tb_writer = SummaryWriter('logs/{}/CLASS'.format(pcae_exp.model_name))\n",
    "pcae_exp.train(train_loader, eval_loader, tb_writer, n_epoch=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[.1, .9], [.9, .1]])\n",
    "b = torch.tensor([1, 0])\n",
    "criterion(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "490a2d67657ae1827c15c39a575b88ef4d8137379e6c26766dfd5a0c94be6691"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('ThermalAnalysis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
